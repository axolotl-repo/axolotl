#!/bin/bash

usage="-w work_dir
             The working directory to run the test. Default will be the current directory.
       -t single_test
             Run single test from input. Default will run the test case that relevant from bugs. Format for pytest: <test_file_path>::<test_method>. Format for unittest: <test_file_path_without.py>.<test_class>.<test_method> . Use bugsinpy-info to get the information about the project.
       -a
             Run all test case in the project. Default will run the test case that relevant from bugs
       -r
             Run the test case that relevant from bugs (Default)
       -s
             Run single test without re-compile(source file not changed)
       -j cpu
             Run all test case in parallel. Only works with -a option. Default is 1.
       -c
             Collect all tests and exit without running.
"

## Add path settings
export PYTHONNOUSERSITE=1

## Add Skip re-compile(for single directory test without source file changed.)
skip_build="0"
run_all="0"
relevant="0"
parallel_job="1"
collect_only="0"
for arg in "$@"; do
    case $arg in
        -[h?] | --help)
            cat <<- ____HALP
          Usage: ${0##*/} [ --help ]
          $usage
____HALP
            exit 0
            ;;
    esac
done

single_test=""
###Read the flag of checkout
while getopts t:w:j:arsc flag; do
    case "${flag}" in
        w) work_dir=${OPTARG} ;;
        t) single_test=${OPTARG} ;;
        j) parallel_job=${OPTARG} ;;
        a) run_all="1" ;;
        r) relevant="1" ;;
        s) skip_build="1" ;;
        c) collect_only="1" ;;
    esac
done

###Update the work directory
if [ "$work_dir" == "" ]; then
    work_dir=$(pwd)
fi

if [[ $work_dir == */ ]]; then
    temp_work_dir="$work_dir"
    work_dir=${temp_work_dir::-1}
fi

if [[ ! -e "$work_dir/bugsinpy_run_test.sh" ]]; then
    echo "This is not a checkout project folder"
    exit 1
fi

if [[ ! -e "$work_dir/bugsinpy_compile_flag" ]]; then
    echo "You have not compile this project"
    exit 1
fi

if [[ "$relevant" == "1" ]]; then
    run_all="0"
    single_test=""
fi

###Activate environment
cd "$work_dir"
default_conda_path=$HOME/anaconda3
conda_path="${CONDA_PATH:-$default_conda_path}"
source $conda_path/etc/profile.d/conda.sh
# Generate unique hash for the current enviroment
bug_python_version=$(grep -o "3\..\.." "bugsinpy_bug.info")
conda_env_name="$(grep -oP "(?<=project_name=).*" bugsinpy_bug.info)_$(grep -oP "(?<=bug_id=).*" bugsinpy_bug.info)"
project_name=$(grep -oP "(?<=project_name=).*" bugsinpy_bug.info)
bug_id=$(grep -oP "(?<=bug_id=).*" bugsinpy_bug.info)

if ! conda activate $conda_env_name; then
    echo "conda env not found, please run bugsinpy-compile first"
    exit 1
fi

if [[ $project_name == "matplotlib" ]]; then
    export MPLLOCALFREETYPE=1
fi

if [[ "$skip_build" == "0" ]]; then
    echo "Running install script..."
    ###Read and run setup.sh to apply the source change
    run_setup_all=""
    if [[ -f "bugsinpy_install.sh" ]]; then
        DONE=false
        until $DONE; do
            read || DONE=true
            run_setup_all+="$REPLY;"
            echo $REPLY
        done < "bugsinpy_install.sh"
    fi

    IFS=';' read -r -a run_setup <<< "$run_setup_all"

    for index in "${!run_setup[@]}"; do
        run_setup_trail=${run_setup[index]}
        run_setup_now=$(echo $run_setup_trail | sed -e 's/\r//g')
        MPLLOCALFREETYPE=1 $run_setup_now
    done

    pip install pytest-cov
else
    echo "[INFO] Skip install due to -s (skip build) flag (no-source file changed)."
fi

pytest="0"
#read file run_test.sh
run_command_all=""
DONE=false
until $DONE; do
    read || DONE=true
    if [ "$REPLY" != "" ]; then
        run_command_all+="$REPLY;"
        if [[ "$REPLY" == *"pytest"* || "$REPLY" == *"py.test"* ]]; then
            pytest="1"
        fi
        # echo $REPLY
    fi
done < "bugsinpy_run_test.sh"
IFS=';' read -r -a run_command <<< "$run_command_all"

rm -f "bugsinpy_fail.txt"
rm -f "bugsinpy_test.txt"
rm -f "bugsinpy_alltest.txt"
rm -f "bugsinpy_singletest.txt"

final_result=0

if [[ "$run_all" == "0" && "$single_test" == "" ]]; then
    #run every command on the run_test.sh
    run_command_filter=""
    echo "Run related tests..."
    for index in "${!run_command[@]}"; do
        run_command_trail=${run_command[index]}
        run_command_now=$(echo $run_command_trail | sed -e 's/\r//g' | sed 's|-q||g')

        res_first=$($run_command_now 2>&1)
        test_result=$?
        echo "$run_command_now: $test_result"

        if [[ $test_result -ne 0 ]]; then
            final_result=1
        fi

        if [[ ${res_first##*$'\n'} == *"OK"* || ${res_first##*$'\n'} == *"pass"* || $res_first == *"passed"* || $res_first == *"OK "* ]]; then
            run_command_filter+="$run_command_now;"
        fi
        echo "BugsInPy test: $run_command_now: $test_result" &>> "bugsinpy_test.txt"
        echo "$res_first" &>> "bugsinpy_test.txt"
    done
elif [[ $collect_only == "1" ]]; then
    if [[ -f "bugsinpy_alltest_collector.json" ]]; then
        rm "bugsinpy_alltest_collector.json"
    fi
    if [[ "$pytest" == "1" ]]; then
        if [[ "$project_name" == "ansible" ]]; then
            echo "python -m pytest test/units/" &>> "bugsinpy_alltest.txt"
            PYTHONPATH=./lib python -m pytest --collect-only test/units/ --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ $project_name == "fastapi" ]]; then
            echo "python -m pytest" &>> "bugsinpy_alltest.txt"
            PYTHONPATH=./docs/src python -m pytest --collect-only --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "httpie" && $bug_id == "5" ]]; then
            echo "python -m pytest test/units/" &>> "bugsinpy_alltest.txt"
            python -m pytest --collect-only tests/tests.py --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "httpie" ]]; then
            echo "python -m pytest tests/" &>> "bugsinpy_alltest.txt"
            python -m pytest --collect-only tests/ --ignore tests/test_ssl.py --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "luigi" ]]; then
            echo "python -m pytest" &>> "bugsinpy_alltest.txt"
            python -m pytest --collect-only test --ignore test/db_task_history_test.py --ignore test/esindex_test.py \
                --ignore test/redshift_test.py --ignore test/s3_test.py \
                --ignore test/contrib/hadoop_test.py \
                --ignore test/contrib/hdfs/ \
                --ignore collecting test/contrib/sqla_test.py \
                --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "pandas" ]]; then
            # if [[ "$bug_id" == "150" || "$bug_id" == "160" || "$bug_id" == "162" || "$bug_id" == "168" ]]; then
            #    echo "pytest pandas --ignore=pandas/tests/io/test_parquet.py" &>>"bugsinpy_alltest.txt"
            #    pytest pandas --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
            #       --json-report-omit log collectors warnings --ignore=pandas/tests/io/test_parquet.py \
            #       --ignore pandas/tests/io/test_common.py 2>&1 | tee -a "bugsinpy_alltest.txt"
            # else
            echo "pytest pandas" &>> "bugsinpy_alltest.txt"
            pytest --collect-only pandas --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings --ignore pandas/tests/io \
                2>&1 | tee -a "bugsinpy_alltest.txt"
            # fi
        elif [[ "$project_name" == "sanic" && $bug_id == "5" ]]; then
            echo "python -m pytest " &>> "bugsinpy_alltest.txt"
            python -m pytest --collect-only --ignore tests/test_redirect.py --ignore tests/test_server_events.py --ignore tests/test_signal_handlers.py \
                --ignore tests/test_worker.py --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "tqdm" ]]; then
            echo "python -m pytest tqdm/tests/tests_*.py" &>> "bugsinpy_alltest.txt"
            python -m pytest --collect-only tqdm/tests/tests_*.py --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        else
            echo "python -m pytest" &>> "bugsinpy_alltest.txt"
            python -m pytest --collect-only --json-report --json-report-file=bugsinpy_alltest_collector.json --json-report-indent=4 \
                --json-report-omit log warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        fi
    else
        echo "Run Unittest"
        ###Read bug.info file
        DONE=false
        until $DONE; do
            read || DONE=true
            if [[ "$REPLY" == "test_file"* ]]; then
                test_file_all="$(cut -d'"' -f 2 <<< $REPLY)"
                IFS=';' read -r -a test_file <<< "$test_file_all"
                test_file_now=${test_file[0]}
            fi
        done < "bugsinpy_bug.info"

        echo "$test_file_now"
        stop_loop_test="0"
        access_test=""
        if [[ "$test_file_now" != "" ]]; then
            IFS='/' read -r -a test_file_ex <<< "$test_file_now"
        fi

        for index in "${!test_file_ex[@]}"; do
            test_file_temp=${test_file_ex[index]}
            if [[ "$stop_loop_test" == "0" ]]; then
                if [[ "$test_file_temp" == *".py"* ]]; then
                    stop_loop_test="1"
                else
                    if [[ "$test_file_temp" == "test" || "$test_file_temp" == "tests" ]]; then
                        stop_loop_test="1"
                    fi
                    access_test+="$test_file_temp/"
                fi
            fi
        done

        echo "$access_test"
        echo "python -m unittest discover -s $access_test" | tee -a "bugsinpy_alltest.txt"
        python bugsinpy_unittest_collector.py $access_test 2>&1 | tee -a "bugsinpy_alltest.txt"
        # echo "python -m unittest discover $access_test"
        # if [[ "$project_name" == "black" ]]; then
        #    echo "python -m unittest discover -s $access_test"
        #    res_first=$(python -m unittest discover $access_test 2>&1)
        #    echo "$res_first"
        #    echo "python -m unittest discover $access_test" &>>"bugsinpy_alltest.txt"
        #    echo "$res_first" &>>"bugsinpy_alltest.txt"
        # else
        #    echo "unittest-parallel -t $work_dir -s $access_test -j $parallel_job"
        #    echo "unittest-parallel -t $work_dir -s $access_test -j $parallel_job" &>>"bugsinpy_alltest.txt"
        #    # res_first=$(python -m unittest discover $access_test 2>&1)
        #    unittest-parallel -t $work_dir -s $access_test -j $parallel_job 2>&1 | tee "bugsinpy_alltest.txt"
        #    #python -m unittest
        #    test_result=${PIPESTATUS[0]}
        # fi

        if [[ $test_result -ne 0 ]]; then
            final_result=1
        fi
    fi
elif [[ "$run_all" == "1" ]]; then
    echo "Run every test..."
    if [[ -f "bugsinpy_alltest_result.json" ]]; then
        rm "bugsinpy_alltest_result.json"
    fi
    if [[ "$pytest" == "1" ]]; then
        if [[ "$project_name" == "ansible" ]]; then
            echo "python -m pytest test/units/" &>> "bugsinpy_alltest.txt"
            PYTHONPATH=./lib python -m pytest test/units/ --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ $project_name == "fastapi" ]]; then
            echo "python -m pytest" &>> "bugsinpy_alltest.txt"
            PYTHONPATH=./docs/src python -m pytest --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "httpie" && $bug_id == "5" ]]; then
            echo "python -m pytest test/units/" &>> "bugsinpy_alltest.txt"
            python -m pytest tests/tests.py --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "httpie" ]]; then
            echo "python -m pytest tests/" &>> "bugsinpy_alltest.txt"
            python -m pytest tests/ --ignore tests/test_ssl.py --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "luigi" ]]; then
            echo "python -m pytest" &>> "bugsinpy_alltest.txt"
            python -m pytest test --ignore test/task_serialize_test.py --ignore test/_mysqldb_test.py \
                --ignore test/contrib/azureblob_test.py --ignore test/contrib/batch_test.py --ignore test/contrib/ecs_test.py \
                --ignore test/contrib/hdfs/ --ignore test/remote_scheduler_test.py --ignore test/rpc_test.py \
                --ignore test/scheduler_parameter_visibilities_test.py --ignore test/server_test.py \
                --ignore test/visualiser/visualiser_test.py \
                --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "pandas" ]]; then
            # if [[ "$bug_id" == "150" || "$bug_id" == "160" || "$bug_id" == "162" || "$bug_id" == "168" ]]; then
            #    echo "pytest pandas --ignore=pandas/tests/io/test_parquet.py" &>>"bugsinpy_alltest.txt"
            #    pytest pandas --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
            #       --json-report-omit log collectors warnings --ignore=pandas/tests/io/test_parquet.py \
            #       --ignore pandas/tests/io/test_common.py 2>&1 | tee -a "bugsinpy_alltest.txt"
            # else
            echo "pytest pandas" &>> "bugsinpy_alltest.txt"
            pytest pandas --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings --ignore pandas/tests/io \
                2>&1 | tee -a "bugsinpy_alltest.txt"
            # fi
        elif [[ "$project_name" == "sanic" && $bug_id == "5" ]]; then
            echo "python -m pytest " &>> "bugsinpy_alltest.txt"
            python -m pytest --ignore tests/test_redirect.py --ignore tests/test_server_events.py --ignore tests/test_signal_handlers.py \
                --ignore tests/test_worker.py --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        elif [[ "$project_name" == "tqdm" ]]; then
            echo "python -m pytest tqdm/tests/tests_*.py" &>> "bugsinpy_alltest.txt"
            python -m pytest tqdm/tests/tests_*.py --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        else
            echo "python -m pytest" &>> "bugsinpy_alltest.txt"
            python -m pytest --json-report --json-report-file=bugsinpy_alltest_result.json --json-report-indent=4 \
                --json-report-omit log collectors warnings 2>&1 | tee -a "bugsinpy_alltest.txt"
        fi
    else
        echo "Run Unittest"
        ###Read bug.info file
        DONE=false
        until $DONE; do
            read || DONE=true
            if [[ "$REPLY" == "test_file"* ]]; then
                test_file_all="$(cut -d'"' -f 2 <<< $REPLY)"
                IFS=';' read -r -a test_file <<< "$test_file_all"
                test_file_now=${test_file[0]}
            fi
        done < "bugsinpy_bug.info"

        echo "$test_file_now"
        stop_loop_test="0"
        access_test=""
        if [[ "$test_file_now" != "" ]]; then
            IFS='/' read -r -a test_file_ex <<< "$test_file_now"
        fi

        for index in "${!test_file_ex[@]}"; do
            test_file_temp=${test_file_ex[index]}
            if [[ "$stop_loop_test" == "0" ]]; then
                if [[ "$test_file_temp" == *".py"* ]]; then
                    stop_loop_test="1"
                else
                    if [[ "$test_file_temp" == "test" || "$test_file_temp" == "tests" ]]; then
                        stop_loop_test="1"
                    fi
                    access_test+="$test_file_temp/"
                fi
            fi
        done

        echo "$access_test"
        echo "python -m unittest discover -s $access_test" | tee -a "bugsinpy_alltest.txt"
        python bugsinpy_unittest_runner.py $access_test 2>&1 | tee -a "bugsinpy_alltest.txt"
        # echo "python -m unittest discover $access_test"
        # if [[ "$project_name" == "black" ]]; then
        #    echo "python -m unittest discover -s $access_test"
        #    res_first=$(python -m unittest discover $access_test 2>&1)
        #    echo "$res_first"
        #    echo "python -m unittest discover $access_test" &>>"bugsinpy_alltest.txt"
        #    echo "$res_first" &>>"bugsinpy_alltest.txt"
        # else
        #    echo "unittest-parallel -t $work_dir -s $access_test -j $parallel_job"
        #    echo "unittest-parallel -t $work_dir -s $access_test -j $parallel_job" &>>"bugsinpy_alltest.txt"
        #    # res_first=$(python -m unittest discover $access_test 2>&1)
        #    unittest-parallel -t $work_dir -s $access_test -j $parallel_job 2>&1 | tee "bugsinpy_alltest.txt"
        #    #python -m unittest
        #    test_result=${PIPESTATUS[0]}
        # fi

        if [[ $test_result -ne 0 ]]; then
            final_result=1
        fi
    fi
elif [ "$single_test" != "" ]; then
    echo "Run $single_test..."
    if [[ "$pytest" == "1" ]]; then
        res_first=$(pytest "$single_test" 2>&1)
        test_result=$?
        echo "$single_test: $test_result"
        echo "BugsInPy test: $single_test: $test_result" &>> "bugsinpy_singletest.txt"
        echo "$res_first" &>> "bugsinpy_singletest.txt"
    else
        res_first=$(python -m unittest -q "$single_test" 2>&1)
        test_result=$?
        echo "$single_test: $test_result"
        echo "BugsInPy test: $single_test: $test_result" &>> "bugsinpy_singletest.txt"
        echo "$res_first" &>> "bugsinpy_singletest.txt"
    fi

    if [[ $test_result -ne 0 ]]; then
        final_result=1
    fi
fi

###Deactivate the environment
conda deactivate
exit $final_result
